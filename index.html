<!DOCTYPE HTML>
<!--
	Strata by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Jie Su</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Header -->
			<header id="header">
				<div class="inner">
					<a href="#" class="image avatar"><img src="images/avatar.jpg" alt="" /></a>
					<h1><name>I'm Jie Su (苏捷),<br />an assistant professor at ZJUT.</name><br />
					</a></h1>
				</div>
				<nav id="nav">
					<ul>
						<h3>
						<a href="#one" class="active">About</a><br/>
						<h3>
						<a href="#two" class="active">News</a><br/>
						<br/>
						<a href="#three" class="active">Publications</a><br/>
						<br/>
						<!-- <a href="#four" class="active">Recipes</a><br/>
						<br/> -->
						<a href="#five" class="active">Contact</a><br/>	
						</h3>
					</ul>
				</nav>
			</header>

		<!-- Main -->
			<div id="main">

				<!-- One -->
					<section id="one">
						<header class="major">
							<h1>About</h1>
						</header>
						<p><h3>Jie Su is now a assistant professor at the Zhejiang University of Technology. Prior to this, he was very fortunate to be advised by Prof. Rajiv Ranjan and Prof. Graham Morgan at Newcastle University. In 2019, he was a research intern at the ITV, working with Marios Perrakis. I obtained my master’s degree with distinction from University of Southampton under the supervision of Pro. Adam Prugel-Bennett.</h3></p>
						<p><h3>My research lies at the intersection of signal processing and machine learning with a special focus on building intelligent systems that are continual and data-efficient. My research interests include signal processing, video understanding, and ubiquitous computing. </h3></p>
					</section>

				<!-- Two -->
				<section id="two">
						<header class="major">
							<h1>News</h1>
						</header>
						<h3><b><font color="#881900">[12/24]</font></b> I will serve as an Area Chair for ICLR 2025, ICML 2025, and ICCV 2025.
						<h3><b><font color="#881900">[09/24]</font></b> I joined Prof. Kaiming He's group as a Postdoctoral Associate at MIT CSAIL.
						<!-- <h3><b><font color="#881900">[07/24]</font></b> I gave a <mylink><a href="https://event.baai.ac.cn/activities/818" >talk</a></mylink> at BAAI (in Chinese) about our recent work <mylink><a href="https://arxiv.org/pdf/2406.11838" >MAR</a></mylink>. -->
						<h3><b><font color="#881900">[05/24]</font></b> I defended my Ph.D. thesis: Towards a Unified Framework for Visual Recognition and Generation via Masked Generative Modeling.
					</section>

				<!-- Three -->

					<section id="three">
						<h1>Publications</h1>
						<div class="row">

							<article class="col-3 col-12-xsmall work-item">
								<a href="images/tce2024j.png" class="image fit thumb"><img src="images/tce2024j.png" alt="" /></a>
							</article>	
							<article class="col-9 col-12-xsmall work-item">
								<b><font color="#000000">Trustworthy IAP: An Intelligent Applications Profiler to Investigate Vulnerabilities of Consumer Electronic Devices</font></b><br>
								<u><b><font color="#000000">J. Su</b></u></font>, Z. Hong , L. Ye, T. Liu, S. Liang, S. Ji, G. Aujla, R. Beyah, Z. Wen<br/>
								<b><i><font color="#000000">IEEE Transactions on Consumer Electronics (TCE), 2024. </font></i></b><br/>
								<mylink><a href="papers/tce2024j.pdf" >[Paper]</a></mylink>
							</article>

							<article class="col-3 col-12-xsmall work-item">
								<a href="images/grsl2023w.png" class="image fit thumb"><img src="images/grsl2023w.png" alt="" /></a>
							</article>	
							<article class="col-9 col-12-xsmall work-item">
								<b><font color="#000000">Edge-SAR-Assisted Multimodal Fusion for Enhanced Cloud Removal</font></b><br>
								Z. Wen, J. Suo, <u><b><font color="#000000">J. Su</b></u></font>, B. Li, Y. Zhou<br/>
								<b><i><font color="#000000">IEEE Geoscience and Remote Sensing Letters (IGRSL), 2023. </font></i></b><br/>
								<mylink><a href="papers/grsl2023w.pdf" >[Paper]</a></mylink>
							</article>

							<article class="col-3 col-12-xsmall work-item">
								<a href="images/ijcnn2023z.png" class="image fit thumb"><img src="images/ijcnn2023z.png" alt="" /></a>
							</article>	
							<article class="col-9 col-12-xsmall work-item">
								<b><font color="#000000">Towards Few-shot Image captioning with Cycle-based Compositional Semantic Enhancement Framework</font></b><br>
								P. Zhang, Y. Bai, <u><b><font color="#000000">J. Su</b></u></font>, Y. Huang, Y. Long<br/>
								<b><i><font color="#000000">IEEE International Joint Conference on Neural Networks (IJCNN), 2023. </font></i></b><br/>
								<mylink><a href="papers/ijcnn2023z.pdf" >[Paper]</a></mylink>
							</article>

							<article class="col-3 col-12-xsmall work-item">
								<a href="images/msp2023p.png" class="image fit thumb"><img src="images/msp2023p.png" alt="" /></a>
							</article>	
							<article class="col-9 col-12-xsmall work-item">
								<b><font color="#000000">Boosting Signal Modulation Few-Shot Learning with Pre-transformation</font></b><br>
								P. Sun, <u><b><font color="#000000">J. Su</b></u></font>, Z. Wen, Y. Zhou, Z. Hong, S. Yu, H. Zhou<br/>
								<b><i><font color="#000000">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2023 </font></i></b><br/>
								<mylink><a href="papers/msp2023p.pdf" >[Paper]</a></mylink>
							</article>

							<article class="col-3 col-12-xsmall work-item">
								<a href="images/tifs2022h.png" class="image fit thumb"><img src="images/tifs2022h.png" alt="" /></a>
							</article>	
							<article class="col-9 col-12-xsmall work-item">
								<b><font color="#000000">ESP Spoofing: Covert Acoustic Attack on MEMS Gyroscopes in Vehicles</font></b><br>
								Z. Hong, X. Li, Z. Wen, L. Zhou, H. Chen, <u><b><font color="#000000">J. Su†</b></u></font><br/>
								<b><i><font color="#000000">IEEE Transactions on Information Forensics and Security (TIFS), 2022 </font></i></b><br/>
								<mylink><a href="papers/tifs2022h.pdf" >[Paper]</a></mylink>
							</article>


							<article class="col-3 col-12-xsmall work-item">
								<a href="images/bpd2022j.png" class="image fit thumb"><img src="images/bpd2022j.png" alt="" /></a>
							</article>	
							<article class="col-9 col-12-xsmall work-item">
								<b><font color="#000000">Learning Disentangled Behaviour Patterns for Wearable-based Human Activity Recognition</font></b><br>
								<u><b><font color="#000000">J. Su</b></u></font>, Z. Wen, T. Lin, Y. Guan<br/>
								<b><i><font color="#000000">ACM international joint conference on Pervasive and Ubiquitous Computing (UbiComp), 2022 </font></i></b><br/>
								<mylink><a href="papers/bpd2022j.pdf" >[Paper]</a></mylink>
							</article>


							<article class="col-3 col-12-xsmall work-item">
								<a href="images/csur2020b.png" class="image fit thumb"><img src="images/csur2020b.png" alt="" /></a>
							</article>	
							<article class="col-9 col-12-xsmall work-item">
								<b><font color="#000000">Orchestrating the Development Lifecycle of Machine Learning-based IoT Applications: A Taxonomy and Survey</font></b><br>
								B. Qian, <u><b><font color="#000000">J. Su</b></u></font>, Z. Wen, D. Jha, Y. Li, Y. Guan, D. Puthal, P. James, R. Yang, A. Zomaya, O. Rana, M. Koutny, R. Ranjan<br />
								<b><i><font color="#000000">ACM Computing Surveys (CSUR), 2020 </font></i></b><br/>
								<mylink><a href="papers/csur2020b.pdf" >[Paper]</a></mylink>
							</article>
							<!-- <article class="col-3 col-12-xsmall work-item">
								<a href="images/mar.png" class="image fit thumb"><img src="images/mar.png" alt="" /></a>
							</article>	
							<article class="col-9 col-12-xsmall work-item">
								<b><font color="#000000">Autoregressive Image Generation without Vector Quantization</font></b><br>
								<u><b><font color="#000000">T. Li</b></u></font>, Y. Tian, H. Li, M. Deng, and K. He<br>
								<b><i><font color="#000000">Neural Information Processing Systems (Neurips), 2024 </font></i></b><br />
								<mylink><a href="https://arxiv.org/abs/2406.11838" >[Paper]</a></mylink>
								<mylink><a href="https://github.com/LTH14/mar" >[Code]</a></mylink>
								<mylink><a href="https://colab.research.google.com/github/LTH14/mar/blob/main/demo/run_mar.ipynb" >[Demo]</a></mylink>
								<mylink><a href="https://huggingface.co/jadechoghari/mar" >[Hugging Face]</a></mylink>
								<mylink><a href="https://event.baai.ac.cn/activities/818" >[Talk]]</a></mylink> 
								<br><b><font color="#881900">Spotlight Presentation (top 2%)</font></b>
							</article>

							<article class="col-3 col-12-xsmall work-item">
								<a href="images/rcg.png" class="image fit thumb"><img src="images/rcg.png" alt="" /></a>
							</article>	
							<article class="col-9 col-12-xsmall work-item">
								<b><font color="#000000">Return of Unconditional Generation: A Self-supervised Representation Generation Method</font></b><br>
								<u><b><font color="#000000">T. Li</b></u></font>, D. Katabi, and K. He<br>
								<b><i><font color="#000000">Neural Information Processing Systems (Neurips), 2024 </font></i></b><br />
								<mylink><a href="https://arxiv.org/abs/2312.03701" >[Paper]</a></mylink>
								<mylink><a href="https://github.com/LTH14/rcg" >[Code]</a></mylink>
								<br><b><font color="#881900">Oral Presentation (top 0.4%)</font></b>
							</article>

							<article class="col-3 col-12-xsmall work-item">
								<a href="images/itit.jpg" class="image fit thumb"><img src="images/itit.jpg" alt="" /></a>
							</article>	
							<article class="col-9 col-12-xsmall work-item">
								<b><font color="#000000">Leveraging Unpaired Data for Vision-Language Generative Models via Cycle Consistency</font></b><br>
								<u><b><font color="#000000">T. Li</b></u></font>, S. Bhardwaj, Y. Tian, H. Zhang, J. Barber, D. Katabi, G. Lajoie, H. Chang, and D. Krishnan<br>
								<b><i><font color="#000000">International Conference on Learning Representations (ICLR), 2024 </font></i></b><br />
								<mylink><a href="https://arxiv.org/abs/2310.03734" >[Paper]</a></mylink>
								<br><b><font color="#881900">Spotlight Presentation (top 5%)</font></b>
							</article>

							<article class="col-3 col-12-xsmall work-item">
								<a href="images/reparo.jpg" class="image fit thumb"><img src="images/reparo.jpg" alt="" /></a>
							</article>	
							<article class="col-9 col-12-xsmall work-item">
								<b><font color="#000000">Reparo: Loss-Resilient Generative Codec for Video Conferencing</font></b><br>
								<u><b><font color="#000000">T. Li</b></u></font>, V. Sivaraman, L. Fan, M. Alizadeh, and D. Katabi<br>
								<mylink><a href="https://arxiv.org/abs/2305.14135" >[Paper]</a></mylink>
							</article>

							<article class="col-3 col-12-xsmall work-item">
								<a href="images/mage.jpg" class="image fit thumb"><img src="images/mage.jpg" alt="" /></a>
							</article>	
							<article class="col-9 col-12-xsmall work-item">
								<b><font color="#000000">MAGE: MAsked Generative Encoder to Unify Representation Learning and Image Synthesis</font></b><br>
								<u><b><font color="#000000">T. Li</b></u></font>, H. Chang, S. K. Mishra, H. Zhang, D. Katabi and D. Krishnan<br>
								<i><b><font color="#000000">Computer Vision and Pattern Recognition (CVPR), 2023</font></b></i><br>
								<mylink><a href="https://arxiv.org/abs/2211.09117" >[Paper]</a></mylink>
								<mylink><a href="https://github.com/LTH14/mage" >[Code]</a></mylink>
								<mylink><a href="https://news.mit.edu/2023/computer-vision-system-marries-image-recognition-generation-0628" >[MIT News]</a></mylink>
							</article>

							<article class="col-3 col-12-xsmall work-item">
								<a href="images/tsc.png" class="image fit thumb"><img src="images/tsc.png" alt="" /></a>
							</article>	
							<article class="col-9 col-12-xsmall work-item">
								<b><font color="#000000">Targeted Supervised Contrastive Learning for Long-Tailed Recognition</font></b><br>
								<u><b><font color="#000000">T. Li</b></u>*</font>, P. Cao*, Y. Yuan, L. Fan, Y. Yang, R. Feris, P. Indyk and D. Katabi<br>
								<i><b><font color="#000000">Computer Vision and Pattern Recognition (CVPR), 2022</font></b></i><br>
								<mylink><a href="https://arxiv.org/abs/2111.13998" >[Paper]</a></mylink>
								<mylink><a href="https://github.com/LTH14/targeted-supcon" >[Code]</a></mylink>
							</article>

							<article class="col-3 col-12-xsmall work-item">
								<a href="images/rcl.jpg" class="image fit thumb"><img src="images/rcl.jpg" alt="" /></a>
							</article>	
							<article class="col-9 col-12-xsmall work-item">
								<b><font color="#000000">Making Contrastive Learning Robust to Shortcuts</font></b><br>
								<u><b><font color="#000000">T. Li</b></u>*</font>, L. Fan*, Y. Yuan, H. He, Y. Tian, R. Feris, P. Indyk and D. Katabi<br>
								<i><b><font color="#000000">Winter Conference on Applications of Computer Vision (WACV), 2023</font></b></i><br>
								<font color="#4183C4"><a href="https://arxiv.org/abs/2012.09962">[Paper]</a></font> <font color="#4183C4"><a href="https://www.youtube.com/watch?v=wbtAOIS16LY"> [Talk] </a></font>
							</article>

							<article class="col-3 col-12-xsmall work-item">
								<a href="images/rfrcl.jpg" class="image fit thumb"><img src="images/rfrcl.jpg" alt="" /></a>
							</article>	
							<article class="col-9 col-12-xsmall work-item">
								<b><font color="#000000">Unsupervised Learning for Human Sensing Using Radio Signals</font></b><br>
								<u><b><font color="#000000">T. Li</b></u>*</font>, L. Fan*, Y. Yuan* and D. Katabi<br>
								<i><b><font color="#000000">Winter Conference on Applications of Computer Vision (WACV), 2022</font></b></i><br>
								<mylink><a href="papers/rfrcl.pdf" >[Paper]</a></mylink>
							</article>
							
							<article class="col-3 col-12-xsmall work-item">
								<a href="images/rfcaption.jpg" class="image fit thumb"><img src="images/rfcaption.jpg" alt="" /></a>
							</article>	
							<article class="col-9 col-12-xsmall work-item">
								<b><font color="#000000">In-Home Daily-Life Captioning Using Radio Signals</font></b><br>
								L. Fan*, <u><b><font color="#000000">T. Li</b></u>*</font>, Y. Yuan and D. Katabi<br>
								<i><b><font color="#000000">European Conference on Computer Vision (ECCV), 2020</font></b></i><br>
								<font color="#4183C4"><a href="http://rf-diary.csail.mit.edu/" class="hove">[Project Page]</a></font>  <font color="#4183C4"><a href="http://rf-diary.csail.mit.edu/papers/rfdiary_eccv.pdf">[PDF]</a></font> <font color="#4183C4"><a href="https://arxiv.org/abs/2008.10966">[arXiv]</a></font> <font color="#4183C4"><a href="http://rf-diary.csail.mit.edu/slides/longtalk.pdf"> [Slides] </a></font>  <font color="#4183C4"><a href="https://youtu.be/j528nQs4_a8"> [Demo] </a></font> <font color="#4183C4"><a href="https://youtu.be/LA-JW4_ovAQ"> [Video] </a></font> <font color="#4183C4"><a href="https://youtu.be/S2Y-zPJnl9U"> [Talk] </a></font>  <font color="#4183C4"><a href="https://www.csail.mit.edu/news/device-nursing-homes-can-monitor-residents-activities-permission-and-without-video"> [CSAIL News]</a></font>  <font color="#4183C4"><a href="https://techcrunch.com/2020/08/24/mit-wireless-system-can-monitor-what-care-facility-residents-are-doing-while-preserving-privacy/"> [TechCrunch]</a></font>  <font color="#4183C4"><a href="https://www.engadget.com/mit-wireless-signals-monitoring-machine-learning-rf-diary-040049578.html"> [Engadget]</a></font>  <font color="#4183C4"><a href="https://venturebeat.com/2020/08/24/mit-csails-rf-diary-monitors-people-through-walls-and-in-total-darkness/"> [VentureBeat]</a></font> 
								<br><b><font color="#881900">Oral Presentation</font></b>
							</article>

							<article class="col-3 col-12-xsmall work-item">
								<a href="images/rfreid.jpg" class="image fit thumb"><img src="images/rfreid.jpg" alt="" /></a>
							</article>	
							<article class="col-9 col-12-xsmall work-item">
								<b><font color="#000000">Learning Longterm Representations for Person Re-Identification Using Radio Signals</font></b><br />
								L. Fan*, <u><b><font color="#000000">T. Li</b></u>*</font>, R. Fang*, R. Hristov, Y. Yuan and D. Katabi<br />
								<i><b><font color="#000000">Computer Vision and Pattern Recognition (CVPR), 2020</font></b></i><br />
								<font color="#4183C4"><a href="http://rf-reid.csail.mit.edu/" class="hove">[Project Page]</a></font> <font color="#4183C4"><a href="http://rf-reid.csail.mit.edu/papers/rfreid_cvpr.pdf">[PDF]</a></font> <font color="#4183C4"><a href="https://arxiv.org/abs/2004.01091">[arXiv]</a></font> <font color="#4183C4"><a href="https://youtu.be/oYv30obQ8P4"> [Video]</a></font> <font color="#4183C4"><a href="https://www.csail.mit.edu/news/home-health-device-uses-wireless-signals-identify-person-its-seen"> [CSAIL News]</a></font> 
								<!-- <mylink><a href="papers/rfreid.pdf" >[PDF]</a></mylink>
								<mylink><a href="http://rf-reid.csail.mit.edu/" >[Website]</a></mylink>
								<mylink><a href="https://arxiv.org/abs/2004.01091" >[Arxiv]</a></mylink>
								<mylink><a href="https://www.youtube.com/watch?v=oYv30obQ8P4" >[Video]</a></mylink> -->
							<!-- </article>

							<article class="col-3 col-12-xsmall work-item">
								<a href="images/fskd.jpg" class="image fit thumb"><img src="images/fskd.jpg" alt="" /></a>
							</article>	
							<article class="col-9 col-12-xsmall work-item">
								<b><font color="#000000">Label-Free Few Sample Knowledge Distillation for Efficient Network Compression</font></b><br />			
								<u><b><font color="#000000">T. Li</b></u></font>, J. Li, Z. Liu, C. Zhang<br />
								<i><b><font color="#000000">Computer Vision and Pattern Recognition (CVPR), 2020</font></b></i><br />
								<mylink><a href="papers/fskd.pdf" >[PDF]</a></mylink>
								<mylink><a href="https://github.com/LTH14/FSKD" >[Code]</a></mylink>
								<mylink><a href="https://arxiv.org/abs/1812.01839" >[Arxiv]</a></mylink>
							</article>

							<article class="col-3 col-12-xsmall work-item">
								<a href="images/rfaction.jpg" class="image fit thumb"><img src="images/rfaction.jpg" alt="" /></a>
							</article>	
							<article class="col-9 col-12-xsmall work-item">
								<b><font color="#000000">Making the Invisible Visible: Action Recognition Through Walls and Occlusions</font></b><br />
								<u><b><font color="#000000">T. Li</b></u>*</font>, L. Fan*, M. Zhao, Y. Liu and D. Katabi<br />
								<b><i><font color="#000000">International Conference on Computer Vision (ICCV), 2019</font></b></i><br />
								<font color="#4183C4"><a href="http://rf-action.csail.mit.edu/" class="hove">[Project Page]</a></font> <font color="#4183C4"><a href="http://rf-action.csail.mit.edu/papers/rfaction_iccv.pdf">[PDF]</a></font> <font color="#4183C4"><a href="https://arxiv.org/abs/1909.09300">[arXiv]</a></font> <font color="#4183C4"><a href="https://youtu.be/UzjBi3xjWR4">[Video]</a></font> <font color="#4183C4"><a href="https://www.technologyreview.com/2019/10/09/132696/machine-vision-has-learned-to-use-radio-waves-to-see-through-walls-and-in-darkness/">[MIT Technology Review]</a></font>
								<!-- <mylink><a href="papers/rfaction.pdf" >[PDF]</a></mylink> -->
<!-- 								<mylink><a href="http://rf-action.csail.mit.edu/" >[Website]</a></mylink>
								<mylink><a href="https://arxiv.org/abs/1909.09300" >[Arxiv]</a></mylink>
								<mylink><a href="https://www.youtube.com/watch?v=UzjBi3xjWR4" >[Video]</a></mylink> -->
							<!-- </article>

							<article class="col-3 col-12-xsmall work-item">
								<a href="images/rfshape.jpg" class="image fit thumb"><img src="images/rfshape.jpg" alt="" /></a>
							</article>	
							<article class="col-9 col-12-xsmall work-item">
								<b><font color="#000000">Through-Wall Human Mesh Recovery Using Radio Signals</font></b><br />
								M. Zhao, Y. Liu, A. Raghu, <u><b><font color="#000000">T. Li</b></u></font>, H. Zhao, A. Torralba and D. Katabi<br />
								<i><b><font color="#000000">International Conference on Computer Vision (ICCV), 2019</font></b></i><br />
								<mylink><a href="papers/rfavatar.pdf" >[PDF]</a></mylink>
								<mylink><a href="http://rfavatar.csail.mit.edu/" >[Website]</a></mylink>
								<mylink><a href="https://arxiv.org/abs/1909.09300" >[Arxiv]</a></mylink>
							</article>

							<article class="col-3 col-12-xsmall work-item">
								<a href="images/rfskeleton.jpg" class="image fit thumb"><img src="images/rfskeleton.jpg" alt="" /></a>
							</article>	
							<article class="col-9 col-12-xsmall work-item">
								<b><font color="#000000">RF-Based 3D Skeletons</font></b><br />
								M. Zhao, Y. Tian, H. Zhao, M. Alsheikh, <u><b><font color="#000000">T. Li</b></u></font>, R. Hristov, Z. Kabelac, D. Katabi and A. Torralba<br />
								<i><b><font color="#000000">ACM SIGCOMM, 2018</font></b></i><br />
								<mylink><a href="papers/rfskeleton.pdf" >[PDF]</a></mylink>
								<mylink><a href="http://rfpose3d.csail.mit.edu/" >[Website]</a></mylink>
							</article>

							<article class="col-3 col-12-xsmall work-item">
								<a href="images/2dskeleton.jpg" class="image fit thumb"><img src="images/2dskeleton.jpg" alt="" /></a>
							</article>	
							<article class="col-9 col-12-xsmall work-item">
								<b><font color="#000000">Through-Wall Human Pose Estimation Using Radio Signals</font></b><br />
								M. Zhao, <u><b><font color="#000000">T. Li</b></u></font>, M. Alsheikh, Y. Tian, H. Zhao, A. Torralba and D. Katabi<br />
								<i><b><font color="#000000">Computer Vision and Pattern Recognition (CVPR), 2018 </font></b></i><br />
								<mylink><a href="papers/rfpose.pdf" >[PDF]</a></mylink>
								<mylink><a href="http://rfpose.csail.mit.edu/" >[Website]</a></mylink>
								<br><b><font color="#881900">Spotlight Presentation</font></b>
							</article>

							<article class="col-3 col-12-xsmall work-item">
								<a href="images/msdnet.jpg" class="image fit thumb"><img src="images/msdnet.jpg" alt="" /></a>
							</article>	
							<article class="col-9 col-12-xsmall work-item">
								<b><font color="#000000">Multi-Scale Dense Networks for Resource Efficient Image Classification</font></b><br />
								G. Huang, D. Chen, <u><b><font color="#000000">T. Li</b></u></font>, F. Wu, L. Maaten, K. Weinberger<br />
								<b><i><font color="#000000">International Conference on Learning Representations (ICLR), 2018 </font></i></b><br />
								<mylink><a href="papers/msdnet.pdf" >[PDF]</a></mylink>
								<mylink><a href="https://github.com/gaohuang/MSDNet" >[Github]</a></mylink>
								<br><b><font color="#881900">Oral Presentation</font></b>
							</article> --> -->
						</div>
					<br />
					<br />
					<br />
					<!-- </section> -->

					<section id="five">
						<h1>Contact</h1>
						<h3>MIT Schwarzman College of Computing<br />
						51 Vassar Street, 733 <br />
						Cambridge, MA 02139 <br />
						tianhong[at]mit.edu
					</section>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.poptrox.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>